{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb541f6",
   "metadata": {},
   "source": [
    "Importar todas las librerias necesarias para correr el script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d053a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para cargar el Dataset\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Para manejar los datos mas facilmente con pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Para ejecutar el modelo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Para evaluar el modelo\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453ef078",
   "metadata": {},
   "source": [
    "Cargue del Dataset, conversion a Dataframe e impresión de las primeras 5 lineas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a43939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta relativa del archivo dentro del dataset\n",
    "file_path = \"cs448b_ipasn.csv\"\n",
    "\n",
    "# Cargar el dataset directamente como DataFrame\n",
    "df = kagglehub.load_dataset(\n",
    "    KaggleDatasetAdapter.PANDAS,\n",
    "    \"crawford/computer-network-traffic\",\n",
    "    file_path\n",
    ")\n",
    "\n",
    "# Ver los primeros registros\n",
    "print(\"Primeras 5 filas:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bde20b",
   "metadata": {},
   "source": [
    "Convertir la fecha y agregar etiquetas sobre los casos comprometidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e2f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna 'date' a formato datetime, el cual es un formato legible y comparable por python\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Definir fechas de compromiso por IP local (l_ipn), estas son IP determinadas como comprometidas en la fecha en la que se empezaron a considerar comprometidas\n",
    "compromised_dates = {\n",
    "    1: '2006-08-24',\n",
    "    5: '2006-09-04',\n",
    "    4: '2006-09-18',\n",
    "    3: '2006-09-26',\n",
    "    6: '2006-09-26'\n",
    "}\n",
    "\n",
    "# Crear la columna 'compromised'\n",
    "# Se agrega un parámetro de comprometido al dataframe, el cual funciona como un booleano, se marca 1 para comprometida y 0 a no comprometida. \n",
    "def label_compromised(row):\n",
    "    ip = row['l_ipn']\n",
    "    date = row['date']\n",
    "    if ip in compromised_dates and date >= pd.to_datetime(compromised_dates[ip]):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df['compromised'] = df.apply(label_compromised, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed6dcd7",
   "metadata": {},
   "source": [
    "Procesamiento del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23858c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar la cantidad de flujos (f)\n",
    "# Para este caso, la normalizacion consiste en transformar los valores de la cantidad de flujos de red por día específico (f) \n",
    "# convirtiendo esta información en un rango de 0 a 1 para facilitar la comprensión de los valores\n",
    "df['f_norm'] = (df['f'] - df['f'].min()) / (df['f'].max() - df['f'].min())\n",
    "\n",
    "# Variables para entrenamiento\n",
    "# Se toman las variables x para las variables independientes que en este caso sería el flujo de conexiones normalizado\n",
    "# Tambien se toma la variable dependiente y que sería correspondiente a si la IP está comprometida o no posterior a la fecha determinada\n",
    "X = df[['f_norm']]\n",
    "y = df['compromised']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d3d51f",
   "metadata": {},
   "source": [
    "Dividir los datos y entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8311262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en entrenamiento y prueba\n",
    "# En este caso se divide el dataset en 75% datos de entrenamiento y 25% datos de prueba para entrenar el modelo y probarlo con los datos que no ha visto\n",
    "# random_state Permite reproducir la misma división de datos cada vez que se corra el código, es como una semilla para \"mantener la aleatoriedad controlada\".\n",
    "# stratify Asegura que la proporción de clases se mantenga en train y test, de modo que no exista un desbalance entre los datos de prueba y entrenamiento con respecto a la variable dependiente.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "# Entrenar modelo de regresión logística\n",
    "# Se crea y se entrena tambien el modelo, en este caso de regresión logística del cual buscamos que aprenda una relacion entre f_norm y la probabilidad de que la IP estuviera o no comprometida\n",
    "model = LogisticRegression(class_weight=\"balanced\", random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "# Se definen las variables y_pred correspondiente a los valores finales de predicción \n",
    "# y \"y_prob\" la cual es la probabilidad de que cada fila esté comprometida con valores entre 0 y 1 \n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6b6864",
   "metadata": {},
   "source": [
    "Evaluacion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1289f7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reporte de clasificación\n",
    "# Se ejecutan una serie de métricas importadas al inicio, con las cuales se puede identificar la presicion, sensibilidad, score y la matriz de confusion\n",
    "\n",
    "print(\"Reporte de clasificación:\\n\",classification_report(y_test, y_pred))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Curva ROC\n",
    "# Esta curva ayuda a determinar que tan bien separa el modelo casos comprometidos de casos normales\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "\n",
    "# Esto último se encarga de presentar o dibujar la curva ROC\n",
    "plt.plot(fpr, tpr, label=f\"ROC AUC = {roc_auc:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Curva ROC - Regresión logística\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
